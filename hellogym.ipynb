{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zifengliu\\AppData\\Local\\anaconda3\\lib\\site-packages\\gymnasium\\envs\\registration.py:523: DeprecationWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  logger.deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.02727336 -0.20172954  0.03625453  0.32351476] 1.0\n",
      "0 [ 0.02323877 -0.39734846  0.04272482  0.62740684] 1.0\n",
      "0 [ 0.0152918  -0.5930399   0.05527296  0.9332334 ] 1.0\n",
      "1 [ 0.003431   -0.39870548  0.07393762  0.6584189 ] 1.0\n",
      "0 [-0.00454311 -0.5947744   0.087106    0.9734366 ] 1.0\n",
      "1 [-0.01643859 -0.4009223   0.10657474  0.7093377 ] 1.0\n",
      "0 [-0.02445704 -0.5973463   0.12076149  1.0335757 ] 1.0\n",
      "1 [-0.03640397 -0.4040192   0.141433    0.78111464] 1.0\n",
      "1 [-0.04448435 -0.21109524  0.1570553   0.53606105] 1.0\n",
      "1 [-0.04870626 -0.01848977  0.16777653  0.29669333] 1.0\n",
      "1 [-0.04907605  0.17389272  0.17371039  0.06126681] 1.0\n",
      "0 [-0.04559819 -0.02323915  0.17493571  0.40332884] 1.0\n",
      "1 [-0.04606298  0.16902632  0.1830023   0.17050143] 1.0\n",
      "1 [-0.04268245  0.36112162  0.18641232 -0.05932718] 1.0\n",
      "1 [-0.03546002  0.55314964  0.18522578 -0.28789067] 1.0\n",
      "1 [-0.02439703  0.74521375  0.17946796 -0.51691335] 1.0\n",
      "0 [-0.00949275  0.5480791   0.1691297  -0.17347981] 1.0\n",
      "1 [ 0.00146883  0.7404276   0.1656601  -0.40839848] 1.0\n",
      "0 [ 0.01627738  0.54339194  0.15749213 -0.0684096 ] 1.0\n",
      "1 [ 0.02714522  0.73594654  0.15612395 -0.3075553 ] 1.0\n",
      "1 [ 0.04186415  0.9285393   0.14997284 -0.5472166 ] 1.0\n",
      "1 [ 0.06043494  1.1212714   0.1390285  -0.78914267] 1.0\n",
      "0 [ 0.08286037  0.9245418   0.12324566 -0.4561528 ] 1.0\n",
      "0 [ 0.1013512   0.72791255  0.1141226  -0.12730356] 1.0\n",
      "0 [0.11590945 0.53135633 0.11157653 0.19909208] 1.0\n",
      "1 [ 0.12653658  0.7247203   0.11555837 -0.05641477] 1.0\n",
      "1 [ 0.14103098  0.918012    0.11443007 -0.31052002] 1.0\n",
      "1 [ 0.15939122  1.1113335   0.10821968 -0.5650367 ] 1.0\n",
      "1 [ 0.18161789  1.3047839   0.09691894 -0.8217604 ] 1.0\n",
      "1 [ 0.20771357  1.4984558   0.08048373 -1.0824552 ] 1.0\n",
      "0 [ 0.23768269  1.3023691   0.05883463 -0.7656407 ] 1.0\n",
      "1 [ 0.26373008  1.4966338   0.04352181 -1.039246  ] 1.0\n",
      "0 [ 0.29366276  1.3009614   0.0227369  -0.733224  ] 1.0\n",
      "1 [ 0.31968197  1.4957619   0.00807242 -1.0186652 ] 1.0\n",
      "0 [ 0.34959722  1.3005333  -0.01230089 -0.7234585 ] 1.0\n",
      "0 [ 0.37560788  1.1055837  -0.02677006 -0.4346725 ] 1.0\n",
      "0 [ 0.39771956  0.9108507  -0.03546351 -0.1505472 ] 1.0\n",
      "0 [ 0.41593656  0.716254   -0.03847445  0.13074017] 1.0\n",
      "0 [ 0.43026164  0.5217037  -0.03585965  0.41104093] 1.0\n",
      "1 [ 0.4406957   0.7173152  -0.02763883  0.10727188] 1.0\n",
      "0 [ 0.45504203  0.5226     -0.02549339  0.39110833] 1.0\n",
      "0 [ 0.465494    0.32784897 -0.01767123  0.67564577] 1.0\n",
      "0 [ 0.472051    0.13297696 -0.00415831  0.962713  ] 1.0\n",
      "1 [0.47471055 0.32815456 0.01509595 0.6687266 ] 1.0\n",
      "0 [0.48127362 0.13282597 0.02847048 0.9661242 ] 1.0\n",
      "0 [ 0.48393014 -0.06266655  0.04779297  1.2676133 ] 1.0\n",
      "0 [ 0.48267683 -0.2583653   0.07314523  1.574872  ] 1.0\n",
      "0 [ 0.4775095  -0.45427912  0.10464267  1.8894426 ] 1.0\n",
      "0 [ 0.46842393 -0.65037054  0.14243153  2.2126794 ] 1.0\n",
      "0 [ 0.45541653 -0.8465404   0.18668512  2.545688  ] 1.0\n",
      "1 [ 0.4384857  -0.6533475   0.23759887  2.315501  ] 1.0\n",
      "reset!\n",
      "0 [-0.03963102 -0.14792429  0.0266861   0.32941288] 1.0\n",
      "1 [-0.04258951  0.04680781  0.03327436  0.04526351] 1.0\n",
      "0 [-0.04165335 -0.14877509  0.03417963  0.34825632] 1.0\n",
      "1 [-0.04462885  0.04584447  0.04114475  0.06654434] 1.0\n",
      "1 [-0.04371196  0.24035311  0.04247564 -0.21287856] 1.0\n",
      "1 [-0.0389049   0.43484285  0.03821807 -0.49186593] 1.0\n",
      "0 [-0.03020804  0.23920324  0.02838075 -0.18738745] 1.0\n",
      "1 [-0.02542398  0.4339079   0.024633   -0.47098398] 1.0\n",
      "1 [-0.01674582  0.6286734   0.01521332 -0.7558023 ] 1.0\n",
      "1 [-4.1723521e-03  8.2358241e-01  9.7275675e-05 -1.0436593e+00] 1.0\n",
      "1 [ 0.0122993   1.018703   -0.02077591 -1.3363117 ] 1.0\n",
      "1 [ 0.03267336  1.2140805  -0.04750215 -1.6354223 ] 1.0\n",
      "0 [ 0.05695496  1.019547   -0.0802106  -1.3579116 ] 1.0\n",
      "1 [ 0.07734591  1.2155781  -0.10736883 -1.6745695 ] 1.0\n",
      "0 [ 0.10165747  1.0218538  -0.14086021 -1.4171622 ] 1.0\n",
      "1 [ 0.12209454  1.2184107  -0.16920346 -1.7503535 ] 1.0\n",
      "0 [ 0.14646275  1.0255661  -0.20421053 -1.5147264 ] 1.0\n",
      "1 [ 0.16697408  1.2224895  -0.23450506 -1.8635952 ] 1.0\n",
      "reset!\n",
      "1 [-0.03728786  0.19034341 -0.01206667 -0.2540547 ] 1.0\n",
      "1 [-0.033481    0.38563555 -0.01714776 -0.5505191 ] 1.0\n",
      "0 [-0.02576829  0.1907586  -0.02815814 -0.26328787] 1.0\n",
      "1 [-0.02195311  0.38627094 -0.0334239  -0.5647175 ] 1.0\n",
      "0 [-0.01422769  0.19163348 -0.04471825 -0.28274918] 1.0\n",
      "1 [-0.01039502  0.3873638  -0.05037323 -0.58919394] 1.0\n",
      "1 [-0.00264775  0.58315355 -0.06215711 -0.89730954] 1.0\n",
      "1 [ 0.00901532  0.77906054 -0.0801033  -1.2088649 ] 1.0\n",
      "1 [ 0.02459653  0.9751204  -0.10428061 -1.525537  ] 1.0\n",
      "0 [ 0.04409894  0.78140044 -0.13479134 -1.2671385 ] 1.0\n",
      "1 [ 0.05972695  0.97796196 -0.1601341  -1.5988151 ] 1.0\n",
      "1 [ 0.07928619  1.174578   -0.19211042 -1.9368443 ] 1.0\n",
      "0 [ 0.10277775  0.98195887 -0.2308473  -1.7093647 ] 1.0\n",
      "reset!\n",
      "1 [ 0.01503204  0.2274788  -0.0062041  -0.32173902] 1.0\n",
      "1 [ 0.01958161  0.42268854 -0.01263888 -0.616372  ] 1.0\n",
      "1 [ 0.02803538  0.6179848  -0.02496632 -0.9130087 ] 1.0\n",
      "0 [ 0.04039508  0.4232093  -0.0432265  -0.6282759 ] 1.0\n",
      "0 [ 0.04885926  0.22871645 -0.05579202 -0.3495137 ] 1.0\n",
      "0 [ 0.05343359  0.03443054 -0.06278229 -0.07493265] 1.0\n",
      "1 [ 0.0541222   0.23039372 -0.06428094 -0.38674417] 1.0\n",
      "1 [ 0.05873008  0.42636648 -0.07201582 -0.69898176] 1.0\n",
      "0 [ 0.0672574   0.23231299 -0.08599546 -0.42981037] 1.0\n",
      "1 [ 0.07190367  0.42854077 -0.09459167 -0.7483159 ] 1.0\n",
      "0 [ 0.08047448  0.23484217 -0.10955799 -0.48683536] 1.0\n",
      "1 [ 0.08517133  0.43132564 -0.1192947  -0.8119392 ] 1.0\n",
      "0 [ 0.09379784  0.23802215 -0.13553348 -0.5590342 ] 1.0\n",
      "1 [ 0.09855828  0.43476012 -0.14671417 -0.89115983] 1.0\n",
      "1 [ 0.10725348  0.6315351  -0.16453736 -1.2261307 ] 1.0\n",
      "0 [ 0.11988419  0.4388685  -0.18905997 -0.98919   ] 1.0\n",
      "1 [ 0.12866156  0.63594896 -0.20884377 -1.3347962 ] 1.0\n",
      "1 [ 0.14138053  0.8329995  -0.23553969 -1.6849043 ] 1.0\n",
      "reset!\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "\n",
    "observation, info = env.reset(seed=42)\n",
    "for _ in range(100):\n",
    "    env.render()\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    print(action, observation, reward)\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        print(\"reset!\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CartPole-v0', 'CartPole-v1', 'MountainCar-v0', 'MountainCarContinuous-v0', 'Pendulum-v1', 'Acrobot-v1', 'CartPoleJax-v0', 'CartPoleJax-v1', 'PendulumJax-v0', 'LunarLander-v2', 'LunarLanderContinuous-v2', 'BipedalWalker-v3', 'BipedalWalkerHardcore-v3', 'CarRacing-v2', 'Blackjack-v1', 'FrozenLake-v1', 'FrozenLake8x8-v1', 'CliffWalking-v0', 'Taxi-v3', 'Jax-Blackjack-v0', 'Reacher-v2', 'Reacher-v4', 'Pusher-v2', 'Pusher-v4', 'InvertedPendulum-v2', 'InvertedPendulum-v4', 'InvertedDoublePendulum-v2', 'InvertedDoublePendulum-v4', 'HalfCheetah-v2', 'HalfCheetah-v3', 'HalfCheetah-v4', 'Hopper-v2', 'Hopper-v3', 'Hopper-v4', 'Swimmer-v2', 'Swimmer-v3', 'Swimmer-v4', 'Walker2d-v2', 'Walker2d-v3', 'Walker2d-v4', 'Ant-v2', 'Ant-v3', 'Ant-v4', 'Humanoid-v2', 'Humanoid-v3', 'Humanoid-v4', 'HumanoidStandup-v2', 'HumanoidStandup-v4', 'GymV21Environment-v0', 'GymV26Environment-v0']\n"
     ]
    }
   ],
   "source": [
    "from gymnasium import envs\n",
    "env_specs = envs.registry.items()\n",
    "# envs_ids = [env_spec.id for _, (k, env_spec) in enumerate(env_specs)]\n",
    "envs_ids = list(envs.registry.keys())\n",
    "print(envs_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "观测空间 = Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n",
      "动作空间 = Discrete(3)\n",
      "# 1 , action =  0 , reward =  -1.0\n",
      "# 2 , action =  0 , reward =  -1.0\n",
      "# 3 , action =  0 , reward =  -1.0\n",
      "# 4 , action =  0 , reward =  -1.0\n",
      "# 5 , action =  0 , reward =  -1.0\n",
      "# 6 , action =  0 , reward =  -1.0\n",
      "# 7 , action =  0 , reward =  -1.0\n",
      "# 8 , action =  0 , reward =  -1.0\n",
      "# 9 , action =  0 , reward =  -1.0\n",
      "# 10 , action =  0 , reward =  -1.0\n",
      "# 11 , action =  0 , reward =  -1.0\n",
      "# 12 , action =  0 , reward =  -1.0\n",
      "# 13 , action =  0 , reward =  -1.0\n",
      "# 14 , action =  0 , reward =  -1.0\n",
      "# 15 , action =  0 , reward =  -1.0\n",
      "# 16 , action =  0 , reward =  -1.0\n",
      "# 17 , action =  0 , reward =  -1.0\n",
      "# 18 , action =  0 , reward =  -1.0\n",
      "# 19 , action =  0 , reward =  -1.0\n",
      "# 20 , action =  0 , reward =  -1.0\n",
      "# 21 , action =  0 , reward =  -1.0\n",
      "# 22 , action =  0 , reward =  -1.0\n",
      "# 23 , action =  0 , reward =  -1.0\n",
      "# 24 , action =  0 , reward =  -1.0\n",
      "# 25 , action =  0 , reward =  -1.0\n",
      "# 26 , action =  0 , reward =  -1.0\n",
      "# 27 , action =  0 , reward =  -1.0\n",
      "# 28 , action =  0 , reward =  -1.0\n",
      "# 29 , action =  0 , reward =  -1.0\n",
      "# 30 , action =  0 , reward =  -1.0\n",
      "# 31 , action =  0 , reward =  -1.0\n",
      "# 32 , action =  0 , reward =  -1.0\n",
      "# 33 , action =  0 , reward =  -1.0\n",
      "# 34 , action =  0 , reward =  -1.0\n",
      "# 35 , action =  0 , reward =  -1.0\n",
      "# 36 , action =  0 , reward =  -1.0\n",
      "# 37 , action =  0 , reward =  -1.0\n",
      "# 38 , action =  0 , reward =  -1.0\n",
      "# 39 , action =  0 , reward =  -1.0\n",
      "# 40 , action =  0 , reward =  -1.0\n",
      "# 41 , action =  2 , reward =  -1.0\n",
      "# 42 , action =  2 , reward =  -1.0\n",
      "# 43 , action =  2 , reward =  -1.0\n",
      "# 44 , action =  2 , reward =  -1.0\n",
      "# 45 , action =  2 , reward =  -1.0\n",
      "# 46 , action =  2 , reward =  -1.0\n",
      "# 47 , action =  2 , reward =  -1.0\n",
      "# 48 , action =  2 , reward =  -1.0\n",
      "# 49 , action =  2 , reward =  -1.0\n",
      "# 50 , action =  2 , reward =  -1.0\n",
      "# 51 , action =  2 , reward =  -1.0\n",
      "# 52 , action =  2 , reward =  -1.0\n",
      "# 53 , action =  2 , reward =  -1.0\n",
      "# 54 , action =  2 , reward =  -1.0\n",
      "# 55 , action =  2 , reward =  -1.0\n",
      "# 56 , action =  2 , reward =  -1.0\n",
      "# 57 , action =  2 , reward =  -1.0\n",
      "# 58 , action =  2 , reward =  -1.0\n",
      "# 59 , action =  2 , reward =  -1.0\n",
      "# 60 , action =  2 , reward =  -1.0\n",
      "# 61 , action =  2 , reward =  -1.0\n",
      "# 62 , action =  2 , reward =  -1.0\n",
      "# 63 , action =  2 , reward =  -1.0\n",
      "# 64 , action =  2 , reward =  -1.0\n",
      "# 65 , action =  2 , reward =  -1.0\n",
      "# 66 , action =  2 , reward =  -1.0\n",
      "# 67 , action =  2 , reward =  -1.0\n",
      "# 68 , action =  2 , reward =  -1.0\n",
      "# 69 , action =  2 , reward =  -1.0\n",
      "# 70 , action =  2 , reward =  -1.0\n",
      "# 71 , action =  2 , reward =  -1.0\n",
      "# 72 , action =  2 , reward =  -1.0\n",
      "# 73 , action =  2 , reward =  -1.0\n",
      "# 74 , action =  2 , reward =  -1.0\n",
      "# 75 , action =  2 , reward =  -1.0\n",
      "# 76 , action =  2 , reward =  -1.0\n",
      "# 77 , action =  2 , reward =  -1.0\n",
      "# 78 , action =  2 , reward =  -1.0\n",
      "# 79 , action =  2 , reward =  -1.0\n",
      "# 80 , action =  2 , reward =  -1.0\n",
      "# 81 , action =  2 , reward =  -1.0\n",
      "# 82 , action =  2 , reward =  -1.0\n",
      "# 83 , action =  2 , reward =  -1.0\n",
      "# 84 , action =  2 , reward =  -1.0\n",
      "# 85 , action =  2 , reward =  -1.0\n",
      "# 86 , action =  2 , reward =  -1.0\n",
      "# 87 , action =  2 , reward =  -1.0\n",
      "# 88 , action =  2 , reward =  -1.0\n",
      "# 89 , action =  2 , reward =  -1.0\n",
      "# 90 , action =  2 , reward =  -1.0\n",
      "# 91 , action =  2 , reward =  -1.0\n",
      "# 92 , action =  2 , reward =  -1.0\n",
      "# 93 , action =  2 , reward =  -1.0\n",
      "# 94 , action =  2 , reward =  -1.0\n",
      "# 95 , action =  2 , reward =  -1.0\n",
      "# 96 , action =  2 , reward =  -1.0\n",
      "# 97 , action =  2 , reward =  -1.0\n",
      "# 98 , action =  2 , reward =  -1.0\n",
      "# 99 , action =  2 , reward =  -1.0\n",
      "# 100 , action =  2 , reward =  -1.0\n",
      "# 101 , action =  2 , reward =  -1.0\n",
      "回合奖励 = -101.0\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make('MountainCar-v0', render_mode=\"human\")\n",
    "print('观测空间 = {}'.format(env.observation_space))\n",
    "print('动作空间 = {}'.format(env.action_space))\n",
    "# print('观测范围 = {} ~ {}'.format(env.observation_space.low, env.observation_space.high))\n",
    "# print('动作数 = {}'.format(env.action_space.n))\n",
    "\n",
    "class BespokeAgent:\n",
    "    def __init__(self, env):\n",
    "        pass\n",
    "    \n",
    "    def decide(self, observation): # 决策\n",
    "        position, velocity = observation\n",
    "        lb = min(-0.09 * (position + 0.25) ** 2 + 0.03,\n",
    "                0.3 * (position + 0.9) ** 4 - 0.008)\n",
    "        ub = -0.07 * (position + 0.38) ** 2 + 0.07\n",
    "        if lb < velocity < ub:\n",
    "            action = 2 # Accelerate to the right\n",
    "        else:\n",
    "            action = 0 # Accelerate to the left\n",
    "        return action # 返回动作\n",
    "    \n",
    "    def decide_cheet(self, epi, observation): # 决策\n",
    "        if epi < 41: # best result: 38 ~ 40\n",
    "            action = 0\n",
    "        else:\n",
    "            action = 2\n",
    "        return action # 返回动作\n",
    "\n",
    "    def learn(self, *args): # 学习\n",
    "        pass\n",
    "    \n",
    "agent = BespokeAgent(env)\n",
    "\n",
    "\n",
    "def play_montecarlo(env, agent, render=False, train=False):\n",
    "    episode_reward = 0. # 记录回合总奖励，初始化为0\n",
    "    observation, _info = env.reset(seed=0) # 重置游戏环境，开始新回合。设置随机数种子,只是为了让结果可以精确复现,一般情况下可删去\n",
    "    # print(observation, type(observation), type(observation[0]))\n",
    "    epi = 0\n",
    "    while True: # 不断循环，直到回合结束\n",
    "        epi += 1\n",
    "        if render: # 判断是否显示\n",
    "            env.render() # 显示图形界面，图形界面可以用 env.close() 语句关闭\n",
    "        # action = agent.decide(observation)\n",
    "        action = agent.decide_cheet(epi, observation)\n",
    "        next_observation, reward, terminated, truncated, _info = env.step(action) # 执行动作\n",
    "        episode_reward += reward # 收集回合奖励\n",
    "        print(\"#\", epi, \", action = \", action, \", reward = \", reward)\n",
    "        if train: # 判断是否训练智能体\n",
    "            agent.learn(observation, action, reward, terminated) # 学习\n",
    "        if terminated: # 回合结束，跳出循环\n",
    "            break\n",
    "        observation = next_observation\n",
    "    return episode_reward # 返回回合总奖励\n",
    "\n",
    "episode_reward = play_montecarlo(env, agent, render=True)\n",
    "print('回合奖励 = {}'.format(episode_reward))\n",
    "env.close() # 此语句可关闭图形界面\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
